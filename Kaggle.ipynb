{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZMnmdDBCl7F"
   },
   "source": [
    "# TBD - Kaggle\n",
    "\n",
    "## Authors\n",
    "| **Name**              | **NIU**   |\n",
    "|-----------------------|-----------|\n",
    "| Arnau Muñoz Barrera   | 1665982   |\n",
    "| José Ortín López      | 1667573   |\n",
    "\n",
    "\n",
    "## Database\n",
    "\n",
    "To access the source Database: [Link to Database](https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required packages in the notebook environment\n",
    "%pip install pandas numpy seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Initial Structure and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/vehicles-dataset.csv', engine='python', on_bad_lines='skip')\n",
    "\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determine columns & their types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Dataset columns & their types: \\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determine quantity of NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar function to display missing values\n",
    "def has_nans(df):\n",
    "    return df.isna().sum().sum() > 0\n",
    "\n",
    "# Auxiliar function to display percentage of missing values per column\n",
    "def get_percentage_nan_per_column(df):\n",
    "    return ((df.isna().sum().sort_values()) / (len(df) * 100))\n",
    "\n",
    "print(\"[INFO] Does the dataset have missing values?\", \"Yes\" if has_nans(df) else \"No\")\n",
    "\n",
    "if has_nans(df):\n",
    "    print(\"\\n [INFO] Percentage of missing values per column: \\n\", get_percentage_nan_per_column(df))\n",
    "\n",
    "    df_missing = pd.DataFrame(list(get_percentage_nan_per_column(df).items()), columns=[\"Field\", \"Percentage\"])\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x=\"Percentage\", y=\"Field\", data=df_missing, palette=\"viridis\")\n",
    "\n",
    "    plt.title(\"Percentage of null values per field\", fontsize=14)\n",
    "    plt.xlabel(\"Percentage (%)\")\n",
    "    plt.ylabel(\"Field\")\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n [INFO] No missing values detected in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "As we can see in previous results, the main initial factors that should be revised & look into are:\n",
    "\n",
    "| **Problem description**                                | **Proposed Solution**      | **Affected fields**      |\n",
    "|--------------------------------------------------------|----------------------------|--------------------------|\n",
    "| Field that needs format clean-up                       | Field modifications        | **posting_date**         |\n",
    "| Field with most NaN values                             | Erase column               | **county**, **VIN**      |\n",
    "| Fields with different types or inconsistent ranges     | Normalization              | **price**, **odometer**  |\n",
    "| Irrelevant fields                                      | Erase column               | **TBD**                  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up ***Posting_date*** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erase ***County*** & ***VIN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['county', 'VIN'], axis=1)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will focus on selecting the appropriate classification metrics and mechanisms to analyze the performance of our final model. To do so, we will train our data using logistic regression and generate a set of functions to evaluate the results, such as graphical functions (Precision-Recall Curve and ROC Curve).\n",
    "\n",
    "The metrics we are going to analyze are the following: Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Coefficient of Determination (R²). Once we obtain the results and functions, we will decide which metric to use in order to select the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration of functions to analyze the metrics:\n",
    "def calculMetriques(y_true, y_pred, metric='mse'):\n",
    "    if metric == 'mse':\n",
    "        result = mean_squared_error(y_true,y_pred)\n",
    "    elif metric == 'rmse':\n",
    "        result = np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "    elif metric == 'mae':\n",
    "        result = mean_absolute_error(y_true,y_pred)\n",
    "    elif metric == 'r2':\n",
    "        result = r2_score(y_true,y_pred)\n",
    "    else:\n",
    "        raise ValueError(\"Métrica no reconocida\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_grafics (y, y_pred):\n",
    "    # Scatter plot between real values (y) and predicted values (y_pred)\n",
    "    plt.scatter(y,y_pred)\n",
    "    # Add a red line representing the ideal line (y = y_pred)\n",
    "    plt.plot(y,y,'--',c = 'red')\n",
    "    plt.xlabel('y_real') # Label for the X-axis\n",
    "    plt.ylabel('y_pred') # Label for the Y-axis\n",
    "    plt.show()           # Display the plot\n",
    "\n",
    "    # Scatter plot of the errors (difference between y_pred and y)\n",
    "    plt.scatter(y,y_pred-y)\n",
    "    plt.xlabel('y_real') \n",
    "    plt.ylabel('error')  # Label for the Y-axis (error)\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter plot of the absolute error (MAE) for each y value\n",
    "    plt.scatter(y,abs(y_pred-y))\n",
    "    plt.xlabel('y_real') \n",
    "    plt.ylabel('MAE')    # Label for the X-axis (Mean Absolute Error)\n",
    "    plt.show()\n",
    "\n",
    "    # Gràfic de dispersió del MAPE (error absolut relatiu per cada valor de y)\n",
    "    plt.scatter(y,abs(y_pred-y)/y)\n",
    "    plt.xlabel('y_real') \n",
    "    plt.ylabel('MAPE')   # Label for the X-axis (Mean Absolute Percentage Error)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL TRAINING #####\n",
    "# Split X and Y\n",
    "target_att = 'price'\n",
    "attributes = [k for k in df.keys() if k!= target_att]\n",
    "X = df[attributes]\n",
    "y = df[[target_att]]\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(X,y)\n",
    "\n",
    "# Evaluate the model performance\n",
    "y_pred = lr.predict(X)\n",
    "\n",
    "# Call to the metric calculation function\n",
    "print(\"Mètriques: \\n\")\n",
    "print(\" Mean Squared Error (MSE):\", calculMetriques(y,y_pred, metric=\"mse\"))\n",
    "print(\" Root Mean Squared Error (RMSE):\", calculMetriques(y,y_pred, metric=\"rmse\"))\n",
    "print(\" Mean Absolute Error (MAE):\", calculMetriques(y,y_pred, metric=\"mae\"))\n",
    "print(\" Coefficient of Determination (R²):\", calculMetriques(y,y_pred, metric=\"r2\"))\n",
    "\n",
    "# Call to the plot generation function\n",
    "mostrar_grafics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop analitzats els resultats amb les diferents mètriques i mecanismes escollirem quina mètrica utilitzarem per avaluar els rendiments dels models i escollir el que més s'adapta al nostre dataset.\n",
    "\n",
    "##### Mètriques escollides per avaluar el nostre model\n",
    "* **Mean Squared Error (MSE)**:\n",
    "\n",
    "    Mesura l'error quadràtic mitjà entre els valors reals i els predits\n",
    "\n",
    "    Ens aporta informació sobre com de grans són els errors, penalitzant especialment els errors grans. També ens dona una idea general de la precisió del model.\n",
    "\n",
    "    $MSE=\\frac{1}{m}\\sum_{i=1}^{m}(y_i-\\hat{y}_i)^2$\n",
    "\n",
    "    <span style=\"color: red;\">✗ *Mètrica no escollida*</span>\n",
    "\n",
    "* **Root Mean Squared Error (RMSE)**:\n",
    "    Arrel quadrada del MSE.\n",
    "\n",
    "    Ens aporta informació de quants euros ens equivoquem de mitjana en les prediccions. És una mètrica útil perquè ens aporta una visió global del rendiment.\n",
    "\n",
    "    $RMSE=\\sqrt{MSE}$\n",
    "\n",
    "    <span style=\"color: red;\">✗ *Mètrica no escollida*</span>\n",
    "\n",
    "* **Mean Absolute Error (MAE)**:\n",
    "    Calcula l'error mitjà en valor absolut\n",
    "    \n",
    "    Ens aporta informació de quant s'equivoca el model de mitjana en valor absolut. A diferència del MSE, no penalitza en excés els outliers. Es una mètrica de gran utilitat quan volem tenir una mesura concreta del comportament global del model sense que els errors molt grans afectin a la mètrica\n",
    "\n",
    "    $MAE=\\frac{1}{m}\\sum_{i=1}^{m}\\lvert y_i-\\hat{y}_i\\rvert$\n",
    "\n",
    "    <span style=\"color: green;\">✔ *Mètrica escollida*</span>\n",
    "\n",
    "* **Coefficient of Determination (R²)**:\n",
    "    Percentatge de la variabilitat del preu és explicat pel model\n",
    "\n",
    "    Ens aporta informació sobre com de bé el model explica l'estructura del dataset. Quan ens trobem amb un R² baix significa que el model no es capaç de capturar la relació entre les variables d'entrades i la variable target (preu). En canvi, quan tenim un R² gran el model es capaç de justificar les variacions en els preus.Es una mètrica de gran utilitat per comparar models amb diferents complexitats \n",
    "    \n",
    "\n",
    "\n",
    "    $R^2 = 1-\\frac{\\sum_{i=1}^{m}(y_i-\\hat{y}i)^2}{\\sum{i=1}^{m}(y_i-\\bar{y})^2}$\n",
    "    \n",
    "    on $\\bar{y}$ és la mitjana dels valors reals\n",
    "\n",
    "    <span style=\"color: red;\">✗ *Mètrica no escollida*</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
